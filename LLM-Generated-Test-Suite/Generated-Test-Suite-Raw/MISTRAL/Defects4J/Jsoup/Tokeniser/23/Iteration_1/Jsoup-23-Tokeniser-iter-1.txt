```java
package org.jsoup.parser;

import org.jsoup.helper.Validate;
import org.jsoup.nodes.Entities;
import org.junit.Before;
import org.junit.Test;
import org.junit.runner.RunWith;
import org.mockito.Mock;
import org.mockito.MockitoAnnotations;
import org.mockito.junit.MockitoJUnitRunner;

import java.util.ArrayList;
import java.util.List;

import static org.junit.Assert.*;
import static org.mockito.Mockito.*;

@RunWith(MockitoJUnitRunner.class)
public class TokeniserTest {

    @Mock
    private CharacterReader reader;

    @Mock
    private ParseErrorList errors;

    private Tokeniser tokeniser;

    @Before
    public void setUp() {
        MockitoAnnotations.initMocks(this);
        tokeniser = new Tokeniser(reader, errors);
    }

    @Test
    public void testRead() {
        when(reader.isEmpty()).thenReturn(false);
        when(reader.current()).thenReturn('a');
        when(reader.pos()).thenReturn(0);

        Token token = tokeniser.read();

        assertNotNull(token);
    }

    @Test
    public void testEmitToken() {
        Token token = new Token.Character("test");
        tokeniser.emit(token);

        assertTrue(tokeniser.isEmitPending);
        assertEquals(token, tokeniser.emitPending);
    }

    @Test
    public void testEmitString() {
        tokeniser.emit("test");

        assertEquals("test", tokeniser.charBuffer.toString());
    }

    @Test
    public void testEmitChar() {
        tokeniser.emit('a');

        assertEquals("a", tokeniser.charBuffer.toString());
    }

    @Test
    public void testGetState() {
        assertEquals(TokeniserState.Data, tokeniser.getState());
    }

    @Test
    public void testTransition() {
        tokeniser.transition(TokeniserState.TagOpen);

        assertEquals(TokeniserState.TagOpen, tokeniser.getState());
    }

    @Test
    public void testAdvanceTransition() {
        tokeniser.advanceTransition(TokeniserState.TagOpen);

        verify(reader).advance();
        assertEquals(TokeniserState.TagOpen, tokeniser.getState());
    }

    @Test
    public void testAcknowledgeSelfClosingFlag() {
        tokeniser.acknowledgeSelfClosingFlag();

        assertTrue(tokeniser.selfClosingFlagAcknowledged);
    }

    @Test
    public void testConsumeCharacterReference() {
        when(reader.isEmpty()).thenReturn(false);
        when(reader.current()).thenReturn('&');
        when(reader.matchConsume("#")).thenReturn(true);
        when(reader.matchConsumeIgnoreCase("X")).thenReturn(false);
        when(reader.consumeDigitSequence()).thenReturn("65");
        when(reader.matchConsume(";")).thenReturn(true);

        Character result = tokeniser.consumeCharacterReference(null, false);

        assertEquals(Character.valueOf('A'), result);
    }

    @Test
    public void testCreateTagPending() {
        Token.Tag tag = tokeniser.createTagPending(true);

        assertNotNull(tag);
        assertTrue(tag instanceof Token.StartTag);
    }

    @Test
    public void testEmitTagPending() {
        tokeniser.createTagPending(true);
        tokeniser.emitTagPending();

        assertTrue(tokeniser.isEmitPending);
    }

    @Test
    public void testCreateCommentPending() {
        tokeniser.createCommentPending();

        assertNotNull(tokeniser.commentPending);
    }

    @Test
    public void testEmitCommentPending() {
        tokeniser.createCommentPending();
        tokeniser.emitCommentPending();

        assertTrue(tokeniser.isEmitPending);
    }

    @Test
    public void testCreateDoctypePending() {
        tokeniser.createDoctypePending();

        assertNotNull(tokeniser.doctypePending);
    }

    @Test
    public void testEmitDoctypePending() {
        tokeniser.createDoctypePending();
        tokeniser.emitDoctypePending();

        assertTrue(tokeniser.isEmitPending);
    }

    @Test
    public void testCreateTempBuffer() {
        tokeniser.createTempBuffer();

        assertNotNull(tokeniser.dataBuffer);
    }

    @Test
    public void testIsAppropriateEndTagToken() {
        tokeniser.createTagPending(true);
        tokeniser.tagPending.tagName = "div";
        tokeniser.lastStartTag = new Token.StartTag();
        tokeniser.lastStartTag.tagName = "div";

        assertTrue(tokeniser.isAppropriateEndTagToken());
    }

    @Test
    public void testAppropriateEndTagName() {
        tokeniser.lastStartTag = new Token.StartTag();
        tokeniser.lastStartTag.tagName = "div";

        assertEquals("div", tokeniser.appropriateEndTagName());
    }

    @Test
    public void testError() {
        tokeniser.error("Test error");

        verify(errors).add(any(ParseError.class));
    }

    @Test
    public void testEofError() {
        tokeniser.eofError(TokeniserState.Data);

        verify(errors).add(any(ParseError.class));
    }

    @Test
    public void testCurrentNodeInHtmlNS() {
        assertTrue(tokeniser.currentNodeInHtmlNS());
    }
}
```